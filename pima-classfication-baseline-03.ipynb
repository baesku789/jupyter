{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 출처\n",
    "   + https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 구성\n",
    "\n",
    "   + Pregnancies : 임신 횟수\n",
    "   + Glucose : 2시간 동안의 경구 포도당 내성 검사에서 혈장 포도당 농도\n",
    "   + BloodPressure : 이완기 혈압 (mm Hg)\n",
    "   + SkinThickness : 삼두근 피부 주름 두께 (mm), 체지방을 추정하는데 사용되는 값\n",
    "   + Insulin : 2시간 혈청 인슐린 (mu U / ml)\n",
    "   + BMI : 체질량 지수 (체중kg / 키(m)^2)\n",
    "   + DiabetesPedigreeFunction : 당뇨병 혈통 기능\n",
    "   + Age : 나이\n",
    "   + Outcome : 768개 중에 268개의 결과 클래스 변수(0 또는 1)는 1이고 나머지는 0입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석을 위한 pandas, 수치계산을 위한 numpy\n",
    "# 시각화를 위한 seaborn, matplotlib.pyplot 을 로드합니다.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes_feature.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습,예측 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome', 'Pregnancies_high',\n",
       "       'Age_low', 'Age_middle', 'Age_high', 'Insulin_nan', 'Insulin_log',\n",
       "       'low_glu_Insulin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Glucose', 'BloodPressure', 'SkinThickness',\n",
    "    'BMI', 'DiabetesPedigreeFunction', 'Age', 'Pregnancies_high',\n",
    "    'Insulin_nan', 'low_glu_Insulin']]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"Outcome\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런에서 제공하는 model_selection 의 train_test_split 으로 만듭니다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 9), (614,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 세트의 문제와 정답의 데이터 수를 확인해 주세요.\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 9), (154,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 세트의 문제와 정답을 확인해 주세요.\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 알고리즘 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree 를 불러옵니다.\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# model = DecisionTreeClassifier(max_depth=11, random_state=42)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적의 max_depth 값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 85.06493506493507\n",
      "4 87.66233766233766\n",
      "5 85.71428571428571\n",
      "6 81.81818181818183\n",
      "7 81.81818181818183\n",
      "8 81.81818181818183\n",
      "9 83.76623376623377\n",
      "10 79.22077922077922\n",
      "11 81.81818181818183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for max_depth in range(3, 12):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    y_predict = model.fit(X_train, y_train).predict(X_test)\n",
    "    score = accuracy_score(y_test, y_predict) * 100\n",
    "    print(max_depth, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 개의 알고리즘을 사용해서 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(random_state=42),\n",
       " RandomForestClassifier(random_state=42),\n",
       " GradientBoostingClassifier(random_state=42)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "\n",
    "estimators = [DecisionTreeClassifier(random_state=42), \n",
    "             RandomForestClassifier(random_state=42), \n",
    "             GradientBoostingClassifier(random_state=42) \n",
    "            ]\n",
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 13, 19, 11,  3,  4,  3, 17,  8, 12])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = np.random.randint(2, 20, 10)\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = np.random.uniform(0.3, 1.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DecisionTreeClassifier'],\n",
       " ['RandomForestClassifier'],\n",
       " ['GradientBoostingClassifier']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for estimator in estimators:\n",
    "    result = []\n",
    "    result.append(estimator.__class__.__name__)\n",
    "    results.append(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': array([ 3,  3, 15, 19, 12,  2, 13,  6, 10, 14]),\n",
       " 'max_features': array([0.41371427, 0.53931203, 0.84130766, 0.77290702, 0.63480147,\n",
       "        0.43903705, 0.99869608, 0.54834406, 0.92657625, 0.88953715]),\n",
       " 'n_estimators': array([965, 876, 816, 997, 111, 199, 896, 985, 143, 614])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions[\"n_estimators\"] = np.random.randint(100, 1000, 10)\n",
    "param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['DecisionTreeClassifier',\n",
       "  {'max_features': 0.9544346115652227, 'max_depth': 4},\n",
       "  0.8714965626652565,\n",
       "  0.8766233766233766,\n",
       "  {'mean_fit_time': array([0.00488691, 0.00718129, 0.00568366, 0.00418823, 0.0050858 ,\n",
       "          0.00368979, 0.00438793, 0.00428841, 0.00518548, 0.00423796]),\n",
       "   'std_fit_time': array([0.00082864, 0.0050023 , 0.00413739, 0.00139628, 0.0017533 ,\n",
       "          0.00063777, 0.00101707, 0.00063903, 0.00087012, 0.00067818]),\n",
       "   'mean_score_time': array([0.0018945 , 0.00249252, 0.0023942 , 0.00199456, 0.00379028,\n",
       "          0.00279241, 0.00199492, 0.00169561, 0.00214822, 0.00189447]),\n",
       "   'std_score_time': array([0.00029938, 0.00080407, 0.00091474, 0.00063136, 0.0037262 ,\n",
       "          0.00193401, 0.00077223, 0.00045736, 0.00063122, 0.00029898]),\n",
       "   'param_max_features': masked_array(data=[0.8663697609341258, 0.992522588655403,\n",
       "                      0.9728729441624215, 0.6325306883958247,\n",
       "                      0.9003614660377156, 0.6325306883958247,\n",
       "                      0.9509874379628416, 0.7045022477991908,\n",
       "                      0.9544346115652227, 0.9728729441624215],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[16, 15, 14, 17, 14, 14, 14, 16, 4, 4],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'max_features': 0.8663697609341258, 'max_depth': 16},\n",
       "    {'max_features': 0.992522588655403, 'max_depth': 15},\n",
       "    {'max_features': 0.9728729441624215, 'max_depth': 14},\n",
       "    {'max_features': 0.6325306883958247, 'max_depth': 17},\n",
       "    {'max_features': 0.9003614660377156, 'max_depth': 14},\n",
       "    {'max_features': 0.6325306883958247, 'max_depth': 14},\n",
       "    {'max_features': 0.9509874379628416, 'max_depth': 14},\n",
       "    {'max_features': 0.7045022477991908, 'max_depth': 16},\n",
       "    {'max_features': 0.9544346115652227, 'max_depth': 4},\n",
       "    {'max_features': 0.9728729441624215, 'max_depth': 4}],\n",
       "   'split0_test_score': array([0.87096774, 0.79032258, 0.79032258, 0.80645161, 0.79032258,\n",
       "          0.80645161, 0.79032258, 0.79032258, 0.83870968, 0.83870968]),\n",
       "   'split1_test_score': array([0.85483871, 0.88709677, 0.88709677, 0.88709677, 0.88709677,\n",
       "          0.88709677, 0.88709677, 0.87096774, 0.82258065, 0.82258065]),\n",
       "   'split2_test_score': array([0.90322581, 0.90322581, 0.90322581, 0.88709677, 0.90322581,\n",
       "          0.88709677, 0.90322581, 0.91935484, 0.85483871, 0.85483871]),\n",
       "   'split3_test_score': array([0.87096774, 0.87096774, 0.87096774, 0.82258065, 0.87096774,\n",
       "          0.82258065, 0.87096774, 0.85483871, 0.87096774, 0.87096774]),\n",
       "   'split4_test_score': array([0.86885246, 0.85245902, 0.85245902, 0.85245902, 0.85245902,\n",
       "          0.85245902, 0.85245902, 0.83606557, 0.81967213, 0.81967213]),\n",
       "   'split5_test_score': array([0.81967213, 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "          0.73770492, 0.75409836, 0.81967213, 0.90163934, 0.90163934]),\n",
       "   'split6_test_score': array([0.83606557, 0.80327869, 0.80327869, 0.81967213, 0.80327869,\n",
       "          0.81967213, 0.80327869, 0.81967213, 0.81967213, 0.81967213]),\n",
       "   'split7_test_score': array([0.8852459 , 0.90163934, 0.90163934, 0.8852459 , 0.90163934,\n",
       "          0.8852459 , 0.90163934, 0.8852459 , 0.91803279, 0.91803279]),\n",
       "   'split8_test_score': array([0.83606557, 0.85245902, 0.85245902, 0.86885246, 0.85245902,\n",
       "          0.86885246, 0.85245902, 0.85245902, 0.93442623, 0.93442623]),\n",
       "   'split9_test_score': array([0.91803279, 0.93442623, 0.93442623, 0.93442623, 0.93442623,\n",
       "          0.93442623, 0.93442623, 0.90163934, 0.93442623, 0.93442623]),\n",
       "   'mean_test_score': array([0.86639344, 0.85499736, 0.85499736, 0.85015865, 0.85499736,\n",
       "          0.85015865, 0.85499736, 0.8550238 , 0.87149656, 0.87149656]),\n",
       "   'std_test_score': array([0.02929592, 0.05398793, 0.05398793, 0.05259454, 0.05398793,\n",
       "          0.05259454, 0.05398793, 0.03811933, 0.0448459 , 0.0448459 ]),\n",
       "   'rank_test_score': array([3, 5, 5, 9, 5, 9, 5, 4, 1, 1])}],\n",
       " ['RandomForestClassifier',\n",
       "  {'n_estimators': 195, 'max_features': 0.9728729441624215, 'max_depth': 15},\n",
       "  0.9022739291380223,\n",
       "  0.8441558441558441,\n",
       "  {'mean_fit_time': array([0.39206157, 0.31186831, 0.24900217, 0.38419025, 0.20624323,\n",
       "          0.25027478, 0.33197808, 0.26374276, 0.17756739, 0.21356399]),\n",
       "   'std_fit_time': array([0.05384652, 0.03823948, 0.03300271, 0.07598361, 0.0463904 ,\n",
       "          0.04549178, 0.06440509, 0.04439843, 0.0106366 , 0.01303129]),\n",
       "   'mean_score_time': array([0.01894956, 0.014888  , 0.01154571, 0.01729012, 0.01119428,\n",
       "          0.01059911, 0.01774318, 0.01289718, 0.01319439, 0.01019437]),\n",
       "   'std_score_time': array([0.0047413 , 0.00198776, 0.00101033, 0.0033969 , 0.00375985,\n",
       "          0.00111909, 0.00773228, 0.00201226, 0.00800759, 0.00085031]),\n",
       "   'param_n_estimators': masked_array(data=[195, 172, 130, 183, 109, 113, 169, 132, 102, 117],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=[0.9728729441624215, 0.7045022477991908,\n",
       "                      0.8663697609341258, 0.8558984899129469,\n",
       "                      0.8558984899129469, 0.992522588655403,\n",
       "                      0.7045022477991908, 0.8663697609341258,\n",
       "                      0.7045022477991908, 0.8558984899129469],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[15, 12, 10, 10, 4, 16, 14, 14, 10, 10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 195,\n",
       "     'max_features': 0.9728729441624215,\n",
       "     'max_depth': 15},\n",
       "    {'n_estimators': 172, 'max_features': 0.7045022477991908, 'max_depth': 12},\n",
       "    {'n_estimators': 130, 'max_features': 0.8663697609341258, 'max_depth': 10},\n",
       "    {'n_estimators': 183, 'max_features': 0.8558984899129469, 'max_depth': 10},\n",
       "    {'n_estimators': 109, 'max_features': 0.8558984899129469, 'max_depth': 4},\n",
       "    {'n_estimators': 113, 'max_features': 0.992522588655403, 'max_depth': 16},\n",
       "    {'n_estimators': 169, 'max_features': 0.7045022477991908, 'max_depth': 14},\n",
       "    {'n_estimators': 132, 'max_features': 0.8663697609341258, 'max_depth': 14},\n",
       "    {'n_estimators': 102, 'max_features': 0.7045022477991908, 'max_depth': 10},\n",
       "    {'n_estimators': 117,\n",
       "     'max_features': 0.8558984899129469,\n",
       "     'max_depth': 10}],\n",
       "   'split0_test_score': array([0.90322581, 0.88709677, 0.87096774, 0.87096774, 0.88709677,\n",
       "          0.87096774, 0.88709677, 0.88709677, 0.87096774, 0.87096774]),\n",
       "   'split1_test_score': array([0.88709677, 0.87096774, 0.88709677, 0.88709677, 0.83870968,\n",
       "          0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.85483871]),\n",
       "   'split2_test_score': array([0.93548387, 0.9516129 , 0.93548387, 0.93548387, 0.93548387,\n",
       "          0.93548387, 0.9516129 , 0.93548387, 0.9516129 , 0.93548387]),\n",
       "   'split3_test_score': array([0.88709677, 0.88709677, 0.88709677, 0.88709677, 0.88709677,\n",
       "          0.88709677, 0.88709677, 0.88709677, 0.88709677, 0.88709677]),\n",
       "   'split4_test_score': array([0.91803279, 0.91803279, 0.91803279, 0.91803279, 0.90163934,\n",
       "          0.91803279, 0.91803279, 0.91803279, 0.90163934, 0.91803279]),\n",
       "   'split5_test_score': array([0.80327869, 0.80327869, 0.81967213, 0.81967213, 0.85245902,\n",
       "          0.81967213, 0.80327869, 0.81967213, 0.80327869, 0.80327869]),\n",
       "   'split6_test_score': array([0.90163934, 0.90163934, 0.8852459 , 0.8852459 , 0.90163934,\n",
       "          0.90163934, 0.90163934, 0.8852459 , 0.90163934, 0.8852459 ]),\n",
       "   'split7_test_score': array([0.90163934, 0.8852459 , 0.90163934, 0.8852459 , 0.90163934,\n",
       "          0.90163934, 0.8852459 , 0.90163934, 0.90163934, 0.90163934]),\n",
       "   'split8_test_score': array([0.93442623, 0.91803279, 0.91803279, 0.91803279, 0.91803279,\n",
       "          0.93442623, 0.91803279, 0.91803279, 0.91803279, 0.91803279]),\n",
       "   'split9_test_score': array([0.95081967, 0.95081967, 0.95081967, 0.95081967, 0.96721311,\n",
       "          0.95081967, 0.95081967, 0.95081967, 0.95081967, 0.95081967]),\n",
       "   'mean_test_score': array([0.90227393, 0.89738234, 0.89740878, 0.89576943, 0.899101  ,\n",
       "          0.89907456, 0.89738234, 0.89740878, 0.89576943, 0.89254363]),\n",
       "   'std_test_score': array([0.03873521, 0.04071807, 0.03503392, 0.03518085, 0.03528669,\n",
       "          0.03695092, 0.04071807, 0.03503392, 0.04075297, 0.0406945 ]),\n",
       "   'rank_test_score': array([ 1,  6,  4,  8,  2,  3,  6,  4,  8, 10])}],\n",
       " ['GradientBoostingClassifier',\n",
       "  {'n_estimators': 163, 'max_features': 0.6325306883958247, 'max_depth': 15},\n",
       "  0.907165520888419,\n",
       "  0.8636363636363636,\n",
       "  {'mean_fit_time': array([0.47201803, 0.47230344, 0.4023201 , 0.6919035 , 0.34603348,\n",
       "          0.43659723, 0.40523069, 0.45868676, 0.53792949, 0.50243752]),\n",
       "   'std_fit_time': array([0.0678351 , 0.05723243, 0.01683145, 0.07719223, 0.02725747,\n",
       "          0.02369875, 0.02655708, 0.06874393, 0.02574399, 0.02709773]),\n",
       "   'mean_score_time': array([0.00259483, 0.00254781, 0.00220513, 0.00289261, 0.00284393,\n",
       "          0.00309191, 0.00269313, 0.00239358, 0.00279291, 0.00268912]),\n",
       "   'std_score_time': array([0.00048573, 0.00064534, 0.00040585, 0.00094105, 0.00178414,\n",
       "          0.00137091, 0.00077914, 0.00066144, 0.00059826, 0.00090054]),\n",
       "   'param_n_estimators': masked_array(data=[135, 123, 109, 185, 101, 117, 116, 117, 163, 149],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=[0.992522588655403, 0.6046477619889719,\n",
       "                      0.9003614660377156, 0.992522588655403,\n",
       "                      0.7045022477991908, 0.9509874379628416,\n",
       "                      0.6046477619889719, 0.9544346115652227,\n",
       "                      0.6325306883958247, 0.6325306883958247],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[7, 14, 17, 16, 14, 16, 14, 14, 15, 15],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'n_estimators': 135,\n",
       "     'max_features': 0.992522588655403,\n",
       "     'max_depth': 7},\n",
       "    {'n_estimators': 123, 'max_features': 0.6046477619889719, 'max_depth': 14},\n",
       "    {'n_estimators': 109, 'max_features': 0.9003614660377156, 'max_depth': 17},\n",
       "    {'n_estimators': 185, 'max_features': 0.992522588655403, 'max_depth': 16},\n",
       "    {'n_estimators': 101, 'max_features': 0.7045022477991908, 'max_depth': 14},\n",
       "    {'n_estimators': 117, 'max_features': 0.9509874379628416, 'max_depth': 16},\n",
       "    {'n_estimators': 116, 'max_features': 0.6046477619889719, 'max_depth': 14},\n",
       "    {'n_estimators': 117, 'max_features': 0.9544346115652227, 'max_depth': 14},\n",
       "    {'n_estimators': 163, 'max_features': 0.6325306883958247, 'max_depth': 15},\n",
       "    {'n_estimators': 149,\n",
       "     'max_features': 0.6325306883958247,\n",
       "     'max_depth': 15}],\n",
       "   'split0_test_score': array([0.87096774, 0.88709677, 0.80645161, 0.79032258, 0.87096774,\n",
       "          0.79032258, 0.88709677, 0.79032258, 0.88709677, 0.88709677]),\n",
       "   'split1_test_score': array([0.90322581, 0.88709677, 0.88709677, 0.87096774, 0.88709677,\n",
       "          0.87096774, 0.88709677, 0.90322581, 0.90322581, 0.90322581]),\n",
       "   'split2_test_score': array([0.93548387, 0.9516129 , 0.91935484, 0.91935484, 0.91935484,\n",
       "          0.91935484, 0.9516129 , 0.91935484, 0.9516129 , 0.9516129 ]),\n",
       "   'split3_test_score': array([0.88709677, 0.90322581, 0.83870968, 0.83870968, 0.85483871,\n",
       "          0.83870968, 0.88709677, 0.83870968, 0.88709677, 0.88709677]),\n",
       "   'split4_test_score': array([0.91803279, 0.91803279, 0.90163934, 0.90163934, 0.93442623,\n",
       "          0.90163934, 0.91803279, 0.90163934, 0.93442623, 0.93442623]),\n",
       "   'split5_test_score': array([0.85245902, 0.81967213, 0.80327869, 0.81967213, 0.80327869,\n",
       "          0.80327869, 0.81967213, 0.80327869, 0.81967213, 0.81967213]),\n",
       "   'split6_test_score': array([0.8852459 , 0.90163934, 0.78688525, 0.78688525, 0.8852459 ,\n",
       "          0.78688525, 0.90163934, 0.78688525, 0.8852459 , 0.8852459 ]),\n",
       "   'split7_test_score': array([0.8852459 , 0.8852459 , 0.91803279, 0.91803279, 0.86885246,\n",
       "          0.91803279, 0.90163934, 0.91803279, 0.91803279, 0.91803279]),\n",
       "   'split8_test_score': array([0.93442623, 0.90163934, 0.86885246, 0.86885246, 0.91803279,\n",
       "          0.86885246, 0.91803279, 0.85245902, 0.93442623, 0.93442623]),\n",
       "   'split9_test_score': array([0.93442623, 0.95081967, 0.91803279, 0.91803279, 0.93442623,\n",
       "          0.91803279, 0.95081967, 0.91803279, 0.95081967, 0.95081967]),\n",
       "   'mean_test_score': array([0.90066103, 0.90060814, 0.86483342, 0.86324696, 0.88765204,\n",
       "          0.86160762, 0.90227393, 0.86319408, 0.90716552, 0.90716552]),\n",
       "   'std_test_score': array([0.02768669, 0.03547821, 0.0494522 , 0.04936192, 0.03890652,\n",
       "          0.05102602, 0.03578073, 0.05261849, 0.03800294, 0.03800294]),\n",
       "   'rank_test_score': array([ 4,  5,  7,  8,  6, 10,  3,  9,  1,  1])}]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "max_depth = np.random.randint(2, 20, 10)\n",
    "max_features = np.random.uniform(0.6, 1.0, 10)\n",
    "\n",
    "param_distributions = {\"max_depth\" : max_depth, \n",
    "                       \"max_features\" : max_features}\n",
    "results = []\n",
    "for estimator in estimators:\n",
    "    result = []\n",
    "    if estimator.__class__.__name__ != 'DecisionTreeClassifier':\n",
    "        param_distributions[\"n_estimators\"] = np.random.randint(100, 200, 100)\n",
    "        \n",
    "    clf = RandomizedSearchCV(estimator,\n",
    "                             param_distributions,\n",
    "                             n_iter=10,  \n",
    "                             scoring=\"accuracy\", \n",
    "                             n_jobs=-1,  \n",
    "                             cv=10, \n",
    "                             verbose=2\n",
    "                      )\n",
    "    clf.fit(X_train, y_train)\n",
    "    result.append(estimator.__class__.__name__)\n",
    "    result.append(clf.best_params_)\n",
    "    result.append(clf.best_score_)\n",
    "    result.append(clf.score(X_test, y_test))\n",
    "    result.append(clf.cv_results_)\n",
    "    results.append(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=[\"estimator\", \"best_params\", \n",
    "                               \"train_score\", \"test_score\", \"cv_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.392062</td>\n",
       "      <td>0.053847</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>195</td>\n",
       "      <td>0.972873</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_estimators': 195, 'max_features': 0.972872...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.902274</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206243</td>\n",
       "      <td>0.046390</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>109</td>\n",
       "      <td>0.855898</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_estimators': 109, 'max_features': 0.855898...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.899101</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.045492</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>113</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_estimators': 113, 'max_features': 0.992522...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.899075</td>\n",
       "      <td>0.036951</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.249002</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>130</td>\n",
       "      <td>0.86637</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 130, 'max_features': 0.866369...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.897409</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263743</td>\n",
       "      <td>0.044398</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>132</td>\n",
       "      <td>0.86637</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_estimators': 132, 'max_features': 0.866369...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.897409</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311868</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>0.014888</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>172</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_estimators': 172, 'max_features': 0.704502...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.897382</td>\n",
       "      <td>0.040718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.331978</td>\n",
       "      <td>0.064405</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>169</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_estimators': 169, 'max_features': 0.704502...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.897382</td>\n",
       "      <td>0.040718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384190</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>183</td>\n",
       "      <td>0.855898</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 183, 'max_features': 0.855898...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.895769</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.177567</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>102</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 102, 'max_features': 0.704502...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.895769</td>\n",
       "      <td>0.040753</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.213564</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>117</td>\n",
       "      <td>0.855898</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 117, 'max_features': 0.855898...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.892544</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.392062      0.053847         0.018950        0.004741   \n",
       "4       0.206243      0.046390         0.011194        0.003760   \n",
       "5       0.250275      0.045492         0.010599        0.001119   \n",
       "2       0.249002      0.033003         0.011546        0.001010   \n",
       "7       0.263743      0.044398         0.012897        0.002012   \n",
       "1       0.311868      0.038239         0.014888        0.001988   \n",
       "6       0.331978      0.064405         0.017743        0.007732   \n",
       "3       0.384190      0.075984         0.017290        0.003397   \n",
       "8       0.177567      0.010637         0.013194        0.008008   \n",
       "9       0.213564      0.013031         0.010194        0.000850   \n",
       "\n",
       "  param_n_estimators param_max_features param_max_depth  \\\n",
       "0                195           0.972873              15   \n",
       "4                109           0.855898               4   \n",
       "5                113           0.992523              16   \n",
       "2                130            0.86637              10   \n",
       "7                132            0.86637              14   \n",
       "1                172           0.704502              12   \n",
       "6                169           0.704502              14   \n",
       "3                183           0.855898              10   \n",
       "8                102           0.704502              10   \n",
       "9                117           0.855898              10   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'n_estimators': 195, 'max_features': 0.972872...           0.903226   \n",
       "4  {'n_estimators': 109, 'max_features': 0.855898...           0.887097   \n",
       "5  {'n_estimators': 113, 'max_features': 0.992522...           0.870968   \n",
       "2  {'n_estimators': 130, 'max_features': 0.866369...           0.870968   \n",
       "7  {'n_estimators': 132, 'max_features': 0.866369...           0.887097   \n",
       "1  {'n_estimators': 172, 'max_features': 0.704502...           0.887097   \n",
       "6  {'n_estimators': 169, 'max_features': 0.704502...           0.887097   \n",
       "3  {'n_estimators': 183, 'max_features': 0.855898...           0.870968   \n",
       "8  {'n_estimators': 102, 'max_features': 0.704502...           0.870968   \n",
       "9  {'n_estimators': 117, 'max_features': 0.855898...           0.870968   \n",
       "\n",
       "   split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0           0.887097  ...           0.887097           0.918033   \n",
       "4           0.838710  ...           0.887097           0.901639   \n",
       "5           0.870968  ...           0.887097           0.918033   \n",
       "2           0.887097  ...           0.887097           0.918033   \n",
       "7           0.870968  ...           0.887097           0.918033   \n",
       "1           0.870968  ...           0.887097           0.918033   \n",
       "6           0.870968  ...           0.887097           0.918033   \n",
       "3           0.887097  ...           0.887097           0.918033   \n",
       "8           0.870968  ...           0.887097           0.901639   \n",
       "9           0.854839  ...           0.887097           0.918033   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.803279           0.901639           0.901639           0.934426   \n",
       "4           0.852459           0.901639           0.901639           0.918033   \n",
       "5           0.819672           0.901639           0.901639           0.934426   \n",
       "2           0.819672           0.885246           0.901639           0.918033   \n",
       "7           0.819672           0.885246           0.901639           0.918033   \n",
       "1           0.803279           0.901639           0.885246           0.918033   \n",
       "6           0.803279           0.901639           0.885246           0.918033   \n",
       "3           0.819672           0.885246           0.885246           0.918033   \n",
       "8           0.803279           0.901639           0.901639           0.918033   \n",
       "9           0.803279           0.885246           0.901639           0.918033   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.950820         0.902274        0.038735                1  \n",
       "4           0.967213         0.899101        0.035287                2  \n",
       "5           0.950820         0.899075        0.036951                3  \n",
       "2           0.950820         0.897409        0.035034                4  \n",
       "7           0.950820         0.897409        0.035034                4  \n",
       "1           0.950820         0.897382        0.040718                6  \n",
       "6           0.950820         0.897382        0.040718                6  \n",
       "3           0.950820         0.895769        0.035181                8  \n",
       "8           0.950820         0.895769        0.040753                8  \n",
       "9           0.950820         0.892544        0.040694               10  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.loc[1, \"cv_result\"]).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   + https://sklearn.org/modules/cross_validation.html#cross-validation\n",
    "   + https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 214 out of 225 | elapsed:    3.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': range(3, 12),\n",
       "                         'max_features': [0.3, 0.5, 0.7, 0.9, 1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\"max_depth\" : range(3,12), \n",
    "              \"max_features\": [0.3, 0.5, 0.7, 0.9, 1]}\n",
    "clf = GridSearchCV(model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 0.7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features=0.7, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664934026389444"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>1.196122e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.7}</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.866493</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>2.849724e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.7}</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012369</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>5.835656e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.9}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.861615</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>3.990662e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.9}</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.859963</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>1.092145e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.7}</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.981833e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.7}</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.858310</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.882081e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.5}</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.856724</td>\n",
       "      <td>0.041834</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>3.994017e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.5}</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.856697</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>1.418448e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.5}</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.855151</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>2.157687e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.5}</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.855151</td>\n",
       "      <td>0.049790</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.883641e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.5}</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.886179</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.853432</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.880529e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.9}</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.853419</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.544772e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.9}</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.851819</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>3.978492e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.5}</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.851819</td>\n",
       "      <td>0.038174</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.887142e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.7}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.851779</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>1.323405e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.7}</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.850273</td>\n",
       "      <td>0.042685</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.004397</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>3.988273e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.9}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.846928</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>1.466395e-03</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.9}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.846928</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>2.325919e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.9}</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.845289</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>2.523457e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.7}</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.843676</td>\n",
       "      <td>0.012701</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.318828e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.9}</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.842050</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>1.596213e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.5}</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.840424</td>\n",
       "      <td>0.049652</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.883058e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.7}</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.840397</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.885193e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.3}</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.840397</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>7.463530e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.5}</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.838811</td>\n",
       "      <td>0.032483</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.307522e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 0.3}</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.835559</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>8.895694e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.5}</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.835492</td>\n",
       "      <td>0.031508</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013563</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>1.351032e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.9}</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.825723</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025931</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>2.034544e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.7}</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.044887</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>1.953370e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.3}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.824124</td>\n",
       "      <td>0.044336</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.888894e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 0.3}</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.822498</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.883054e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 0.3}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.799693</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.889477e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 0.3}</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.799680</td>\n",
       "      <td>0.067140</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>1.177566e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.3}</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.796508</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>2.096999e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.3}</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.794842</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.885012e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 0.3}</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.791603</td>\n",
       "      <td>0.036247</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>9.246216e-07</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 11, 'max_features': 1}</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.762268</td>\n",
       "      <td>0.047002</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>1.163743e-03</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 1}</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.742743</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>6.274362e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 8, 'max_features': 1}</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.745902</td>\n",
       "      <td>0.741050</td>\n",
       "      <td>0.038211</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.991372e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 6, 'max_features': 1}</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.728069</td>\n",
       "      <td>0.035838</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.312792e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 9, 'max_features': 1}</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.724683</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>7.469921e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 1}</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.719845</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.196852e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 1}</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.706877</td>\n",
       "      <td>0.026328</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>1.470289e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 1}</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.700333</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>4.419330e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 1}</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.642276</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.680728</td>\n",
       "      <td>0.031188</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "12       0.005186      0.002475         0.002593    1.196122e-03   \n",
       "7        0.005585      0.001850         0.004188    2.849724e-03   \n",
       "8        0.012369      0.008592         0.005387    5.835656e-03   \n",
       "18       0.004190      0.000399         0.001794    3.990662e-04   \n",
       "27       0.005186      0.002392         0.001994    1.092145e-03   \n",
       "17       0.006981      0.002676         0.001795    3.981833e-04   \n",
       "31       0.003590      0.000798         0.001596    4.882081e-04   \n",
       "11       0.005983      0.004038         0.002195    3.994017e-04   \n",
       "1        0.008971      0.004889         0.009572    1.418448e-02   \n",
       "6        0.008774      0.005796         0.004593    2.157687e-03   \n",
       "21       0.004389      0.000488         0.001595    4.883641e-04   \n",
       "23       0.005585      0.001849         0.001596    4.880529e-04   \n",
       "28       0.005785      0.002706         0.001995    1.544772e-03   \n",
       "36       0.003791      0.000399         0.001794    3.978492e-04   \n",
       "32       0.003989      0.000631         0.001596    4.887142e-04   \n",
       "22       0.004988      0.000894         0.003190    1.323405e-03   \n",
       "38       0.007580      0.004397         0.002194    3.988273e-04   \n",
       "43       0.004787      0.001163         0.002194    1.466395e-03   \n",
       "13       0.003990      0.000631         0.003391    2.325919e-03   \n",
       "37       0.004588      0.000799         0.002992    2.523457e-03   \n",
       "33       0.004189      0.000398         0.001995    6.318828e-04   \n",
       "16       0.004388      0.001850         0.002793    1.596213e-03   \n",
       "42       0.004787      0.000977         0.001596    4.883058e-04   \n",
       "35       0.003790      0.000399         0.001595    4.885193e-04   \n",
       "41       0.005585      0.003191         0.002194    7.463530e-04   \n",
       "20       0.003789      0.000746         0.001995    6.307522e-04   \n",
       "26       0.003992      0.000634         0.001992    8.895694e-04   \n",
       "3        0.013563      0.017213         0.002392    1.351032e-03   \n",
       "2        0.025931      0.018193         0.004187    2.034544e-03   \n",
       "5        0.006383      0.002054         0.004589    1.953370e-03   \n",
       "40       0.004987      0.003025         0.001595    4.888894e-04   \n",
       "30       0.004787      0.001716         0.001596    4.883054e-04   \n",
       "25       0.003391      0.000489         0.001595    4.889477e-04   \n",
       "0        0.010973      0.005388         0.010571    1.177566e-02   \n",
       "10       0.004189      0.000976         0.001994    2.096999e-06   \n",
       "15       0.003391      0.000489         0.001596    4.885012e-04   \n",
       "44       0.005186      0.001716         0.001995    9.246216e-07   \n",
       "39       0.003191      0.000399         0.002194    1.163743e-03   \n",
       "29       0.003793      0.000750         0.001992    6.274362e-04   \n",
       "19       0.003590      0.000489         0.001795    3.991372e-04   \n",
       "34       0.003591      0.000488         0.001995    6.312792e-04   \n",
       "9        0.003988      0.001091         0.001795    7.469921e-04   \n",
       "14       0.003590      0.000797         0.001995    1.196852e-06   \n",
       "24       0.004186      0.000401         0.002197    1.470289e-03   \n",
       "4        0.008581      0.004163         0.009969    4.419330e-03   \n",
       "\n",
       "   param_max_depth param_max_features                                  params  \\\n",
       "12               5                0.7   {'max_depth': 5, 'max_features': 0.7}   \n",
       "7                4                0.7   {'max_depth': 4, 'max_features': 0.7}   \n",
       "8                4                0.9   {'max_depth': 4, 'max_features': 0.9}   \n",
       "18               6                0.9   {'max_depth': 6, 'max_features': 0.9}   \n",
       "27               8                0.7   {'max_depth': 8, 'max_features': 0.7}   \n",
       "17               6                0.7   {'max_depth': 6, 'max_features': 0.7}   \n",
       "31               9                0.5   {'max_depth': 9, 'max_features': 0.5}   \n",
       "11               5                0.5   {'max_depth': 5, 'max_features': 0.5}   \n",
       "1                3                0.5   {'max_depth': 3, 'max_features': 0.5}   \n",
       "6                4                0.5   {'max_depth': 4, 'max_features': 0.5}   \n",
       "21               7                0.5   {'max_depth': 7, 'max_features': 0.5}   \n",
       "23               7                0.9   {'max_depth': 7, 'max_features': 0.9}   \n",
       "28               8                0.9   {'max_depth': 8, 'max_features': 0.9}   \n",
       "36              10                0.5  {'max_depth': 10, 'max_features': 0.5}   \n",
       "32               9                0.7   {'max_depth': 9, 'max_features': 0.7}   \n",
       "22               7                0.7   {'max_depth': 7, 'max_features': 0.7}   \n",
       "38              10                0.9  {'max_depth': 10, 'max_features': 0.9}   \n",
       "43              11                0.9  {'max_depth': 11, 'max_features': 0.9}   \n",
       "13               5                0.9   {'max_depth': 5, 'max_features': 0.9}   \n",
       "37              10                0.7  {'max_depth': 10, 'max_features': 0.7}   \n",
       "33               9                0.9   {'max_depth': 9, 'max_features': 0.9}   \n",
       "16               6                0.5   {'max_depth': 6, 'max_features': 0.5}   \n",
       "42              11                0.7  {'max_depth': 11, 'max_features': 0.7}   \n",
       "35              10                0.3  {'max_depth': 10, 'max_features': 0.3}   \n",
       "41              11                0.5  {'max_depth': 11, 'max_features': 0.5}   \n",
       "20               7                0.3   {'max_depth': 7, 'max_features': 0.3}   \n",
       "26               8                0.5   {'max_depth': 8, 'max_features': 0.5}   \n",
       "3                3                0.9   {'max_depth': 3, 'max_features': 0.9}   \n",
       "2                3                0.7   {'max_depth': 3, 'max_features': 0.7}   \n",
       "5                4                0.3   {'max_depth': 4, 'max_features': 0.3}   \n",
       "40              11                0.3  {'max_depth': 11, 'max_features': 0.3}   \n",
       "30               9                0.3   {'max_depth': 9, 'max_features': 0.3}   \n",
       "25               8                0.3   {'max_depth': 8, 'max_features': 0.3}   \n",
       "0                3                0.3   {'max_depth': 3, 'max_features': 0.3}   \n",
       "10               5                0.3   {'max_depth': 5, 'max_features': 0.3}   \n",
       "15               6                0.3   {'max_depth': 6, 'max_features': 0.3}   \n",
       "44              11                  1    {'max_depth': 11, 'max_features': 1}   \n",
       "39              10                  1    {'max_depth': 10, 'max_features': 1}   \n",
       "29               8                  1     {'max_depth': 8, 'max_features': 1}   \n",
       "19               6                  1     {'max_depth': 6, 'max_features': 1}   \n",
       "34               9                  1     {'max_depth': 9, 'max_features': 1}   \n",
       "9                4                  1     {'max_depth': 4, 'max_features': 1}   \n",
       "14               5                  1     {'max_depth': 5, 'max_features': 1}   \n",
       "24               7                  1     {'max_depth': 7, 'max_features': 1}   \n",
       "4                3                  1     {'max_depth': 3, 'max_features': 1}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "12           0.878049           0.910569           0.813008   \n",
       "7            0.813008           0.886179           0.829268   \n",
       "8            0.821138           0.886179           0.853659   \n",
       "18           0.829268           0.894309           0.821138   \n",
       "27           0.861789           0.878049           0.837398   \n",
       "17           0.861789           0.869919           0.804878   \n",
       "31           0.853659           0.902439           0.780488   \n",
       "11           0.837398           0.878049           0.821138   \n",
       "1            0.780488           0.910569           0.813008   \n",
       "6            0.788618           0.886179           0.804878   \n",
       "21           0.845528           0.886179           0.821138   \n",
       "23           0.829268           0.902439           0.829268   \n",
       "28           0.861789           0.853659           0.821138   \n",
       "36           0.853659           0.894309           0.780488   \n",
       "32           0.821138           0.878049           0.861789   \n",
       "22           0.804878           0.853659           0.804878   \n",
       "38           0.821138           0.878049           0.796748   \n",
       "43           0.821138           0.878049           0.796748   \n",
       "13           0.853659           0.878049           0.788618   \n",
       "37           0.829268           0.845528           0.829268   \n",
       "33           0.829268           0.845528           0.796748   \n",
       "16           0.796748           0.910569           0.772358   \n",
       "42           0.829268           0.845528           0.829268   \n",
       "35           0.788618           0.918699           0.780488   \n",
       "41           0.837398           0.837398           0.780488   \n",
       "20           0.813008           0.861789           0.813008   \n",
       "26           0.869919           0.861789           0.780488   \n",
       "3            0.788618           0.902439           0.804878   \n",
       "2            0.780488           0.902439           0.804878   \n",
       "5            0.821138           0.894309           0.756098   \n",
       "40           0.772358           0.878049           0.756098   \n",
       "30           0.821138           0.804878           0.723577   \n",
       "25           0.821138           0.910569           0.747967   \n",
       "0            0.747967           0.845528           0.764228   \n",
       "10           0.772358           0.845528           0.756098   \n",
       "15           0.731707           0.813008           0.772358   \n",
       "44           0.715447           0.780488           0.699187   \n",
       "39           0.682927           0.804878           0.715447   \n",
       "29           0.715447           0.813008           0.707317   \n",
       "19           0.715447           0.764228           0.666667   \n",
       "34           0.764228           0.747967           0.715447   \n",
       "9            0.723577           0.747967           0.715447   \n",
       "14           0.707317           0.658537           0.707317   \n",
       "24           0.723577           0.691057           0.674797   \n",
       "4            0.691057           0.642276           0.699187   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "12           0.837398           0.893443         0.866493        0.036082   \n",
       "7            0.861789           0.918033         0.861655        0.037935   \n",
       "8            0.853659           0.893443         0.861615        0.026005   \n",
       "18           0.878049           0.877049         0.859963        0.029149   \n",
       "27           0.853659           0.860656         0.858310        0.013162   \n",
       "17           0.894309           0.860656         0.858310        0.029337   \n",
       "31           0.861789           0.885246         0.856724        0.041834   \n",
       "11           0.878049           0.868852         0.856697        0.023222   \n",
       "1            0.853659           0.918033         0.855151        0.053625   \n",
       "6            0.878049           0.918033         0.855151        0.049790   \n",
       "21           0.853659           0.860656         0.853432        0.021118   \n",
       "23           0.853659           0.852459         0.853419        0.026722   \n",
       "28           0.853659           0.868852         0.851819        0.016356   \n",
       "36           0.861789           0.868852         0.851819        0.038174   \n",
       "32           0.853659           0.844262         0.851779        0.018917   \n",
       "22           0.869919           0.918033         0.850273        0.042685   \n",
       "38           0.878049           0.860656         0.846928        0.032584   \n",
       "43           0.878049           0.860656         0.846928        0.032584   \n",
       "13           0.853659           0.852459         0.845289        0.029921   \n",
       "37           0.853659           0.860656         0.843676        0.012701   \n",
       "33           0.878049           0.860656         0.842050        0.027820   \n",
       "16           0.861789           0.860656         0.840424        0.049652   \n",
       "42           0.853659           0.844262         0.840397        0.009642   \n",
       "35           0.869919           0.844262         0.840397        0.051552   \n",
       "41           0.869919           0.868852         0.838811        0.032483   \n",
       "20           0.821138           0.868852         0.835559        0.024582   \n",
       "26           0.837398           0.827869         0.835492        0.031508   \n",
       "3            0.813008           0.819672         0.825723        0.039736   \n",
       "2            0.788618           0.844262         0.824137        0.044887   \n",
       "5            0.813008           0.836066         0.824124        0.044336   \n",
       "40           0.869919           0.836066         0.822498        0.049883   \n",
       "30           0.837398           0.811475         0.799693        0.039600   \n",
       "25           0.715447           0.803279         0.799680        0.067140   \n",
       "0            0.772358           0.852459         0.796508        0.043623   \n",
       "10           0.772358           0.827869         0.794842        0.035134   \n",
       "15           0.804878           0.836066         0.791603        0.036247   \n",
       "44           0.821138           0.795082         0.762268        0.047002   \n",
       "39           0.723577           0.786885         0.742743        0.045825   \n",
       "29           0.723577           0.745902         0.741050        0.038211   \n",
       "19           0.731707           0.762295         0.728069        0.035838   \n",
       "34           0.715447           0.680328         0.724683        0.029134   \n",
       "9            0.707317           0.704918         0.719845        0.015517   \n",
       "14           0.731707           0.729508         0.706877        0.026328   \n",
       "24           0.707317           0.704918         0.700333        0.016421   \n",
       "4            0.723577           0.647541         0.680728        0.031188   \n",
       "\n",
       "    rank_test_score  \n",
       "12                1  \n",
       "7                 2  \n",
       "8                 3  \n",
       "18                4  \n",
       "27                5  \n",
       "17                5  \n",
       "31                7  \n",
       "11                8  \n",
       "1                 9  \n",
       "6                 9  \n",
       "21               11  \n",
       "23               12  \n",
       "28               13  \n",
       "36               13  \n",
       "32               15  \n",
       "22               16  \n",
       "38               17  \n",
       "43               17  \n",
       "13               19  \n",
       "37               20  \n",
       "33               21  \n",
       "16               22  \n",
       "42               23  \n",
       "35               23  \n",
       "41               25  \n",
       "20               26  \n",
       "26               27  \n",
       "3                28  \n",
       "2                29  \n",
       "5                30  \n",
       "40               31  \n",
       "30               32  \n",
       "25               33  \n",
       "0                34  \n",
       "10               35  \n",
       "15               36  \n",
       "44               37  \n",
       "39               38  \n",
       "29               39  \n",
       "19               40  \n",
       "34               41  \n",
       "9                42  \n",
       "14               43  \n",
       "24               44  \n",
       "4                45  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701298701298701"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 14, 14, 12, 19,  5,  4, 11, 14,  5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = np.random.randint(3, 20, 10)\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9147806 , 0.82804594, 0.96041684, 0.75915336, 0.94413359,\n",
       "       0.94790355, 0.85105732, 0.78144766, 0.85457425, 0.73253396,\n",
       "       0.97984689, 0.99462709, 0.85081147, 0.74865335, 0.86660149,\n",
       "       0.88831789, 0.82213702, 0.87982491, 0.9985206 , 0.98254337,\n",
       "       0.80020526, 0.92779016, 0.99441601, 0.77202635, 0.87259458,\n",
       "       0.97832489, 0.86544147, 0.84589049, 0.79227326, 0.73772929,\n",
       "       0.70530575, 0.84976421, 0.70332234, 0.78400129, 0.93507531,\n",
       "       0.75533631, 0.73521348, 0.90674567, 0.74246514, 0.82971749,\n",
       "       0.95497979, 0.914113  , 0.79000049, 0.96783271, 0.95359848,\n",
       "       0.85998464, 0.93124638, 0.736494  , 0.71227586, 0.98487624,\n",
       "       0.84181419, 0.95769105, 0.82680795, 0.74595635, 0.89194751,\n",
       "       0.90824975, 0.76635021, 0.86344444, 0.93985238, 0.78843465,\n",
       "       0.79816208, 0.8184154 , 0.80929473, 0.86305571, 0.80037631,\n",
       "       0.97850468, 0.85825924, 0.8783503 , 0.91812826, 0.9362634 ,\n",
       "       0.9660268 , 0.9638092 , 0.9679882 , 0.77393657, 0.77800294,\n",
       "       0.96682695, 0.94250875, 0.9042981 , 0.98907274, 0.83340374,\n",
       "       0.74621315, 0.81734583, 0.88824124, 0.85466813, 0.95553508,\n",
       "       0.81399518, 0.73231266, 0.7498907 , 0.89592225, 0.75180748,\n",
       "       0.73661696, 0.98500767, 0.72471287, 0.76815468, 0.91063663,\n",
       "       0.78015523, 0.77442571, 0.70539941, 0.96791835, 0.95457371])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = np.random.uniform(0.7, 1.0, 100)\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': array([ 8, 14, 14, 12, 19,  5,  4, 11, 14,  5]),\n",
       " 'max_features': array([0.9147806 , 0.82804594, 0.96041684, 0.75915336, 0.94413359,\n",
       "        0.94790355, 0.85105732, 0.78144766, 0.85457425, 0.73253396,\n",
       "        0.97984689, 0.99462709, 0.85081147, 0.74865335, 0.86660149,\n",
       "        0.88831789, 0.82213702, 0.87982491, 0.9985206 , 0.98254337,\n",
       "        0.80020526, 0.92779016, 0.99441601, 0.77202635, 0.87259458,\n",
       "        0.97832489, 0.86544147, 0.84589049, 0.79227326, 0.73772929,\n",
       "        0.70530575, 0.84976421, 0.70332234, 0.78400129, 0.93507531,\n",
       "        0.75533631, 0.73521348, 0.90674567, 0.74246514, 0.82971749,\n",
       "        0.95497979, 0.914113  , 0.79000049, 0.96783271, 0.95359848,\n",
       "        0.85998464, 0.93124638, 0.736494  , 0.71227586, 0.98487624,\n",
       "        0.84181419, 0.95769105, 0.82680795, 0.74595635, 0.89194751,\n",
       "        0.90824975, 0.76635021, 0.86344444, 0.93985238, 0.78843465,\n",
       "        0.79816208, 0.8184154 , 0.80929473, 0.86305571, 0.80037631,\n",
       "        0.97850468, 0.85825924, 0.8783503 , 0.91812826, 0.9362634 ,\n",
       "        0.9660268 , 0.9638092 , 0.9679882 , 0.77393657, 0.77800294,\n",
       "        0.96682695, 0.94250875, 0.9042981 , 0.98907274, 0.83340374,\n",
       "        0.74621315, 0.81734583, 0.88824124, 0.85466813, 0.95553508,\n",
       "        0.81399518, 0.73231266, 0.7498907 , 0.89592225, 0.75180748,\n",
       "        0.73661696, 0.98500767, 0.72471287, 0.76815468, 0.91063663,\n",
       "        0.78015523, 0.77442571, 0.70539941, 0.96791835, 0.95457371]),\n",
       " 'min_samples_split': [2, 3, 4, 5, 6]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\"max_depth\" : max_depth, \n",
    "                       \"max_features\" : max_features, \n",
    "                       \"min_samples_split\" : list(range(2, 7))}\n",
    "param_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': array([ 8, 14, 14, 12, 19,  5,  4, 11, 14,  5]),\n",
       "                                        'max_features': array([0.9147806 , 0.82804594, 0.96041684, 0.75915336, 0.94413359,\n",
       "       0.94790355, 0.85105732, 0.78144766, 0.85457425, 0.73253396,\n",
       "       0.97984689, 0.99462709, 0.85081147, 0.74865335, 0.86660149,...\n",
       "       0.9660268 , 0.9638092 , 0.9679882 , 0.77393657, 0.77800294,\n",
       "       0.96682695, 0.94250875, 0.9042981 , 0.98907274, 0.83340374,\n",
       "       0.74621315, 0.81734583, 0.88824124, 0.85466813, 0.95553508,\n",
       "       0.81399518, 0.73231266, 0.7498907 , 0.89592225, 0.75180748,\n",
       "       0.73661696, 0.98500767, 0.72471287, 0.76815468, 0.91063663,\n",
       "       0.78015523, 0.77442571, 0.70539941, 0.96791835, 0.95457371]),\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6]},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = RandomizedSearchCV( model,\n",
    "                    param_distributions,\n",
    "                    n_iter=1000,\n",
    "                    scoring=\"accuracy\",\n",
    "                    n_jobs=-1,\n",
    "                    cv=5,\n",
    "                    random_state=42\n",
    "                  )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 4, 'max_features': 0.7459563481471504, 'max_depth': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8697454351592697"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701298701298701"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>4</td>\n",
       "      <td>0.742465</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 0.742...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>4</td>\n",
       "      <td>0.705306</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 0.705...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>4</td>\n",
       "      <td>0.724713</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 0.724...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>4</td>\n",
       "      <td>0.732313</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 0.732...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>4</td>\n",
       "      <td>0.746213</td>\n",
       "      <td>5</td>\n",
       "      <td>{'min_samples_split': 4, 'max_features': 0.746...</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.869745</td>\n",
       "      <td>0.033985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "306       0.003705      0.000407         0.001294        0.000398   \n",
       "886       0.004199      0.001181         0.001803        0.000403   \n",
       "291       0.003206      0.000404         0.001395        0.000486   \n",
       "891       0.004698      0.001077         0.001807        0.001380   \n",
       "153       0.003790      0.001596         0.001397        0.000489   \n",
       "\n",
       "    param_min_samples_split param_max_features param_max_depth  \\\n",
       "306                       4           0.742465               5   \n",
       "886                       4           0.705306               5   \n",
       "291                       4           0.724713               5   \n",
       "891                       4           0.732313               5   \n",
       "153                       4           0.746213               5   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "306  {'min_samples_split': 4, 'max_features': 0.742...           0.878049   \n",
       "886  {'min_samples_split': 4, 'max_features': 0.705...           0.878049   \n",
       "291  {'min_samples_split': 4, 'max_features': 0.724...           0.878049   \n",
       "891  {'min_samples_split': 4, 'max_features': 0.732...           0.878049   \n",
       "153  {'min_samples_split': 4, 'max_features': 0.746...           0.878049   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "306           0.910569           0.813008           0.853659   \n",
       "886           0.910569           0.813008           0.853659   \n",
       "291           0.910569           0.813008           0.853659   \n",
       "891           0.910569           0.813008           0.853659   \n",
       "153           0.910569           0.813008           0.853659   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "306           0.893443         0.869745        0.033985                1  \n",
       "886           0.893443         0.869745        0.033985                1  \n",
       "291           0.893443         0.869745        0.033985                1  \n",
       "891           0.893443         0.869745        0.033985                1  \n",
       "153           0.893443         0.869745        0.033985                1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values(by=\"rank_test_score\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습과 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 시킵니다.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도(Accuracy)측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22c6220d490>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=model.feature_importances_, y=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다르게 예측한 개수를 구해서 diff_count 에 할당해 줍니다.\n",
    "# DT : 28\n",
    "# RF : 20\n",
    "# GB : 24\n",
    "\n",
    "(y_predict != y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.81818181818183"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score 를 구합니다.\n",
    "# DT : 0.818\n",
    "# RF : 0.870\n",
    "# GB : 0.844\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
